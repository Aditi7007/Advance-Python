{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOBGzgYTVRzwzoDYcCxVDOZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","import pandas as pd\n","\n","# Documents\n","documents = [\n","    \"The quick brown fox jumps over the lazy dog.\",\n","    \"The fox is quick and jumps high.\",\n","    \"A lazy dog lies under the tree.\"\n","]\n","\n","# Create TfidfVectorizer\n","vectorizer = TfidfVectorizer()\n","\n","# Fit the vectorizer on the documents and transform them\n","tfidf_matrix = vectorizer.fit_transform(documents)\n","\n","# Convert the matrix to a DataFrame for better readability\n","tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n","\n","# Print the resulting TF-IDF values for each word in each document\n","print(\"TF-IDF Values:\")\n","print(tfidf_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cPxy-_JX9cjI","executionInfo":{"status":"ok","timestamp":1743756057557,"user_tz":-330,"elapsed":548,"user":{"displayName":"ADITI SINGH","userId":"15686955306504732234"}},"outputId":"f7e9e47a-3f3a-4ca4-d0d8-f611fcb058f0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["TF-IDF Values:\n","        and     brown       dog       fox      high        is     jumps  \\\n","0  0.000000  0.398811  0.303306  0.303306  0.000000  0.000000  0.303306   \n","1  0.443503  0.000000  0.000000  0.337295  0.443503  0.443503  0.337295   \n","2  0.000000  0.000000  0.358291  0.000000  0.000000  0.000000  0.000000   \n","\n","       lazy     lies      over     quick       the     tree    under  \n","0  0.303306  0.00000  0.398811  0.303306  0.471089  0.00000  0.00000  \n","1  0.000000  0.00000  0.000000  0.337295  0.261940  0.00000  0.00000  \n","2  0.358291  0.47111  0.000000  0.000000  0.278245  0.47111  0.47111  \n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Define the quadratic function y = 2x^2 + 3x + 4\n","def quadratic_function(x):\n","    return 2 * x**2 + 3 * x + 4\n","\n","# Generate synthetic data for the quadratic function\n","np.random.seed(42)\n","x_data = np.random.uniform(-10, 10, 100)  # Random values between -10 and 10\n","y_data = quadratic_function(x_data)  # Apply the quadratic function to generate y values\n","\n","# Define the quadratic regression model\n","class QuadraticRegression(tf.keras.Model):\n","    def __init__(self):\n","        super(QuadraticRegression, self).__init__()\n","        # Randomly initialize weights and bias\n","        self.w1 = tf.Variable(np.random.randn(), name='w1', dtype=tf.float32)\n","        self.w2 = tf.Variable(np.random.randn(), name='w2', dtype=tf.float32)\n","        self.b = tf.Variable(np.random.randn(), name='b', dtype=tf.float32)\n","\n","    def call(self, x):\n","        return self.w1 * x**2 + self.w2 * x + self.b  # Quadratic relationship\n","\n","# Instantiate the model\n","model = QuadraticRegression()\n","\n","# Define the loss function (Mean Squared Error)\n","def compute_loss(y_true, y_pred):\n","    return tf.reduce_mean(tf.square(y_true - y_pred))\n","\n","# Define the optimizer\n","optimizer = tf.optimizers.Adam(learning_rate=0.01)\n","\n","# Training loop\n","epochs = 5000\n","for epoch in range(epochs):\n","    with tf.GradientTape() as tape:\n","        y_pred = model(x_data)  # Forward pass\n","        loss = compute_loss(y_data, y_pred)  # Calculate the loss\n","\n","    # Compute gradients and update the weights and bias\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","    if epoch % 500 == 0:\n","        print(f\"Epoch {epoch}, Loss: {loss.numpy()}\")\n","\n","# Print the learned parameters\n","print(f\"Learned weights and bias after training:\")\n","print(f\"w1: {model.w1.numpy()}, w2: {model.w2.numpy()}, b: {model.b.numpy()}\")\n","\n","# Plot the original and predicted data\n","plt.scatter(x_data, y_data, label=\"Original Data\", color=\"blue\")\n","plt.plot(x_data, model(x_data), label=\"Fitted Quadratic Model\", color=\"red\")\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.legend()\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"id":"ZWVWIlT19euo","executionInfo":{"status":"error","timestamp":1743756082496,"user_tz":-330,"elapsed":148,"user":{"displayName":"ADITI SINGH","userId":"15686955306504732234"}},"outputId":"c4a10433-888e-495c-89f8-0678c46e0a8a"},"execution_count":3,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"not enough values to unpack (expected 2, got 0)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-6611254123df>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Compute gradients and update the weights and bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Return iterations for compat with tf.keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"]}]}]}